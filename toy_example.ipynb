{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:10.594294Z",
     "start_time": "2023-07-10T11:11:09.554143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import multivariate_normal, multivariate_t, random_correlation\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "import imageio\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is doing the $\\mu$ update of AMIS but with np.einsum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu (np.einsum):\n",
      "[-0.55462523  4.00143026]\n",
      "mu (for loop):\n",
      "[-0.55462523  4.00143026]\n"
     ]
    }
   ],
   "source": [
    "# Define the shapes of the tensors\n",
    "T = 3\n",
    "M = 4\n",
    "D = 2\n",
    "\n",
    "# Create the tensors X and W\n",
    "X = np.random.randn(T, M, D)\n",
    "W = np.random.randn(T, M)\n",
    "\n",
    "# Calculate mu using np.einsum\n",
    "mu_einsum = np.einsum('tmd,tm->d', X, W)\n",
    "\n",
    "# Calculate mu using for loop\n",
    "mu_for_loop = np.zeros(D)\n",
    "for t in range(T):\n",
    "    for m in range(M):\n",
    "        mu_for_loop += W[t, m] * X[t, m, :]\n",
    "\n",
    "# Print the results\n",
    "print(\"mu (np.einsum):\")\n",
    "print(mu_einsum)\n",
    "print(\"mu (for loop):\")\n",
    "print(mu_for_loop)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:25.259446Z",
     "start_time": "2023-07-10T11:11:25.251617Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is doing the $\\Sigma$ update of AMIS but with np.einsum\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov (np.einsum):\n",
      "[[-2.31461765 -4.0684629 ]\n",
      " [-4.0684629  -7.82428435]]\n",
      "cov (for loop):\n",
      "[[-2.31461765 -4.0684629 ]\n",
      " [-4.0684629  -7.82428435]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate cov using np.einsum\n",
    "cov_einsum = np.einsum('tm, tmd, tme -> de', W, X, X)\n",
    "\n",
    "# Calculate cov using for loop\n",
    "cov_for_loop = np.zeros((D, D))\n",
    "for t in range(T):\n",
    "    for m in range(M):\n",
    "        cov_for_loop += W[t, m] * (X[t, m, :].reshape(-1, 1) @ X[t, m, :].reshape(1, -1))\n",
    "\n",
    "# Print the results\n",
    "print(\"cov (np.einsum):\")\n",
    "print(cov_einsum)\n",
    "print(\"cov (for loop):\")\n",
    "print(cov_for_loop)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:26.390569Z",
     "start_time": "2023-07-10T11:11:26.385552Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def save(obj, filename):\n",
    "    \"\"\"Save compiled models for reuse.\"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load(filename):\n",
    "    \"\"\"Reload compiled models for reuse.\"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:27.297903Z",
     "start_time": "2023-07-10T11:11:27.293093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def plot_contour_lines(dist1, dist2, iteration=0):\n",
    "    # Generate a grid of points\n",
    "    x = np.linspace(-10, 10, 100)\n",
    "    y = np.linspace(-10, 10, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "\n",
    "    # Calculate the probability density for each distribution at each point on the grid\n",
    "    Z1 = dist1.pdf(positions.T)\n",
    "    Z2 = dist2.pdf(positions.T)\n",
    "\n",
    "    # Reshape the probability density values to match the grid shape\n",
    "    Z1 = Z1.reshape(X.shape)\n",
    "    Z2 = Z2.reshape(X.shape)\n",
    "\n",
    "    # Create a new figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the contour lines for the first distribution in blue color\n",
    "    ax.contour(X, Y, Z1, colors='blue', label='Proposal')\n",
    "\n",
    "    # Plot the contour lines for the second distribution in red color\n",
    "    ax.contour(X, Y, Z2, colors='red', label='Target')\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_title('Contour Lines')\n",
    "\n",
    "    # # Add a legend in the upper right corner\n",
    "    # ax.legend()\n",
    "\n",
    "    plt.savefig(\"results/ais-heavy-iter-{}.png\".format(iteration), bbox_inches=\"tight\", dpi=100)\n",
    "    # plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:27.735518Z",
     "start_time": "2023-07-10T11:11:27.729832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load any settings\n",
    "with open(\"settings.yaml\", mode=\"r\") as file:\n",
    "    settings = yaml.safe_load(file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:28.248888Z",
     "start_time": "2023-07-10T11:11:28.244586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "D = 2\n",
    "ddof_target = settings['ddof_target']\n",
    "ddof_proposal = ddof_target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:28.586256Z",
     "start_time": "2023-07-10T11:11:28.579962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Target\n",
    "mean_target = np.zeros(D)\n",
    "std_devs_target = np.diag(np.sqrt(np.ones(D)*2))\n",
    "random_corr_mat = random_correlation(eigs=np.ones(D)).rvs(1)\n",
    "cov_target =  std_devs_target @ random_corr_mat  @ std_devs_target\n",
    "shape_target = ((ddof_target - 2) / ddof_target) * cov_target\n",
    "\n",
    "# Proposal\n",
    "mean_proposal = np.ones(D)\n",
    "std_devs_proposal = np.diag(np.sqrt(np.ones(D)*6))\n",
    "# random_corr_mat = random_correlation(eigs= np.ones(D)).rvs(1)\n",
    "cov_proposal = std_devs_proposal @ random_corr_mat @ std_devs_proposal\n",
    "\n",
    "shape_proposal = ((ddof_proposal - 2) / ddof_proposal) * cov_proposal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:28.958650Z",
     "start_time": "2023-07-10T11:11:28.954643Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AMIS\n",
    "\n",
    "From : [https://ieeexplore.ieee.org/abstract/document/8902642?casa_token=gK_xJB2jt34AAAAA:65X9GElDk4_j4odWQmpPAp7nmEr7EXBzAFIwvgrqQdiCllmvO2ozoaF93Rs9t0tAg-2QvBEA_dw](here)\n",
    "\n",
    "Note $\\theta_j = (\\mu_j, \\Sigma_j)$\n",
    "\n",
    "For $t=1,\\dots,T$:\n",
    "\n",
    "* Draw $M$ samples from the current proposal: $x_{t}^{(m)} \\sim q(x, \\theta_t), m=1,\\dots,M$\n",
    "* Weight the samples: $w_{\\tau}^{(m)} = \\frac{\\pi(x_{\\tau}^{(m)})}{(1/t) \\sum_{j=1}^{t} q(x_{\\tau}^{(m)}; \\theta_{j})} $ for $\\tau=1,\\dots,t$ and $m=1,\\dots,M$\n",
    "* Normalize the weights: $\\bar{w}_{\\tau}^{(m)} = \\frac{w_{\\tau}^{(m)}}{\\sum_{j=1}^{t} \\sum_{m=1}^{M} w_{j}^{(m)}}$\n",
    "* Update proposal parameters:\n",
    "    * $\\mu_{t+1} = \\sum_{j=1}^{t} \\sum_{m=1}^{M} \\bar{w}_{j}^{(m)} x_{j}^{(m)}$\n",
    "    * $\\Sigma_{t+1} = \\sum_{j=1}^{t} \\sum_{m=1}^{M} \\bar{w}_{j}^{(m)}  (x_{j}^{(m)} - \\mu_{t+1})(x_{j}^{(m)} - \\mu_{t+1})^\\top $\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def AMIS(mu_initial,shape_initial, n_iterations, target_pdf, ddof_proposal, M=200):\n",
    "    all_normalized_logweights = np.empty((n_iterations,M))\n",
    "    all_logweights = np.empty((n_iterations,M))\n",
    "    all_samples = np.empty((n_iterations,M,D))\n",
    "    evaluations_target_logpdf = np.empty((n_iterations,M))\n",
    "\n",
    "    proposals_over_iterations = []\n",
    "\n",
    "    # Iteration 0\n",
    "    first_proposal = multivariate_t(loc=mu_initial,shape=shape_initial,df=ddof_proposal)\n",
    "    proposals_over_iterations.append(first_proposal)\n",
    "    samples_initial = first_proposal.rvs(size=M)\n",
    "    all_samples[0,:] = samples_initial\n",
    "\n",
    "    log_numerator = target_pdf.logpdf(samples_initial)\n",
    "    evaluations_target_logpdf[0,:] = log_numerator\n",
    "\n",
    "    log_denominator = first_proposal.logpdf(samples_initial) # No temporal mixture in iteration 0\n",
    "\n",
    "    # assert log_numerator.shape == log_denominator.shape\n",
    "    current_logweights = log_numerator - log_denominator\n",
    "    all_logweights[0,:] = current_logweights\n",
    "    all_normalized_logweights[0,:] = current_logweights - logsumexp(current_logweights)\n",
    "\n",
    "    mu_current, shape_current = np.average(samples_initial, weights=np.exp(all_normalized_logweights[0,:]), axis=0), ((ddof_target - 2) / ddof_target) * np.cov(samples_initial, rowvar=False, aweights=np.exp(all_normalized_logweights[0,:]))\n",
    "\n",
    "    # Zero-eth iteration is working\n",
    "\n",
    "    assert mu_current.shape == (D,) and shape_current.shape == (D,D)\n",
    "\n",
    "    # Iteration t > 0\n",
    "    for t in tqdm(range(1,n_iterations)):\n",
    "\n",
    "        current_proposal = multivariate_t(loc=mu_current, shape=shape_current, df=ddof_proposal)\n",
    "\n",
    "        proposals_over_iterations.append(current_proposal)\n",
    "\n",
    "        # Plot current proposal vs target\n",
    "        # plot_contour_lines(current_proposal, target_pdf, iteration=t)\n",
    "\n",
    "        # Draw M samples from current proposal\n",
    "        samples_current = current_proposal.rvs(size=M)\n",
    "        all_samples[t,:] = samples_current # this adds to the existing list of samples, does not override\n",
    "\n",
    "        # Weighting and re-weighting procedure\n",
    "\n",
    "        # Numerator\n",
    "        evaluations_target_logpdf[t,:] = target_pdf.logpdf(samples_current) # this adds to the existing list of target evaluations\n",
    "\n",
    "        log_numerator = evaluations_target_logpdf[:t+1,:] # t+1 since including current ones !\n",
    "\n",
    "        # Note the mixture in the denominator !\n",
    "\n",
    "        def temporal_mixture(x):\n",
    "            evaluations_mixture_component = np.empty((t+1,t+1,M))\n",
    "            for tau in range(0,t+1):\n",
    "                for j in range(0,t+1):\n",
    "                    evaluations_mixture_component[tau,j,:] = proposals_over_iterations[j].logpdf(x[tau,:,:])\n",
    "\n",
    "            # vectorized_evaluations_mixture_component = np.asarray([ proposals_over_iterations[prev_t].logpdf(x) for prev_t in range(0,t+1) ])\n",
    "            # assert np.allclose(vectorized_evaluations_mixture_component, evaluations_mixture_component)\n",
    "\n",
    "            return logsumexp(evaluations_mixture_component,axis=1)\n",
    "\n",
    "        mixture_denominator_evaluations = temporal_mixture(all_samples[:t+1,:,:])\n",
    "\n",
    "        log_denominator = - np.log(t+1) +  mixture_denominator_evaluations  # check correct axis\n",
    "\n",
    "        assert log_numerator.shape == log_denominator.shape\n",
    "\n",
    "        assert all_logweights[:t+1,:].shape == log_numerator.shape\n",
    "\n",
    "        updated_logweights = log_numerator - log_denominator\n",
    "        all_logweights[:t+1,:] = updated_logweights # each iteration updates all weights up to time t\n",
    "\n",
    "        updated_normalized_logweights = updated_logweights - logsumexp(updated_logweights)\n",
    "        all_normalized_logweights[:t+1,:] = updated_normalized_logweights\n",
    "\n",
    "        ### Update proposal\n",
    "        # mu_current, shape_current = np.average(samples_current, weights=np.exp(current_normalized_logweights), axis=0), ((ddof_target - 2) / ddof_target) * np.cov(samples_current, rowvar=False, aweights=np.exp(current_normalized_logweights))\n",
    "\n",
    "        samples_up_to_now = all_samples[:t+1,:,:]\n",
    "\n",
    "        ## SLOW version for debugging:\n",
    "\n",
    "        mu_current = np.zeros(D)\n",
    "        for tau in range(t):\n",
    "            for m in range(M):\n",
    "                mu_current += np.exp(updated_normalized_logweights[tau, m]) * samples_up_to_now[t, m, :]\n",
    "\n",
    "        shape_current = np.zeros((D, D))\n",
    "        for tau in range(t):\n",
    "            for m in range(M):\n",
    "                shape_current += np.exp(updated_normalized_logweights[tau, m]) * (samples_up_to_now[t, m, :].reshape(-1, 1) @ samples_up_to_now[t, m, :].reshape(1, -1))\n",
    "\n",
    "        shape_current = ((ddof_target - 2) / ddof_target) * shape_current\n",
    "\n",
    "        #### Vectorized versions\n",
    "\n",
    "        # mu_current = np.einsum('tmd,tm->d', samples_up_to_now, updated_normalized_logweights)\n",
    "        #\n",
    "        # diff = all_samples[:t+1,:,:] - mu_current.reshape(1, 1, D)\n",
    "        #\n",
    "        # shape_current = ((ddof_target - 2) / ddof_target) * np.einsum('tm, tmd, tme -> de', updated_normalized_logweights, diff, diff)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# plot_contour_lines(multivariate_t(loc=mean_proposal,shape=shape_proposal,df=ddof_proposal), multivariate_t(loc=mean_target,shape=shape_target,df=ddof_target), iteration=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T11:11:40.637808Z",
     "start_time": "2023-07-10T11:11:40.629859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:16<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "AMIS(mu_initial=mean_proposal,shape_initial=shape_proposal, n_iterations=30, target_pdf=multivariate_t(loc=mean_target,shape=shape_target,df=ddof_target), ddof_proposal=ddof_proposal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write movie to a file\n",
    "filenames = [os.path.join(\"results\", \"ais-heavy-iter-{}.png\".format(i)) for i in range(0,150)]\n",
    "\n",
    "with imageio.get_writer(os.path.join(\"results\", 'movie.gif'), mode='I', duration=0.3) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "clip = mp.VideoFileClip(os.path.join(\"results\", 'movie.gif'))\n",
    "clip.write_videofile(os.path.join(\"results\", 'movie.mp4'))\n",
    "# showing clip\n",
    "# clip.ipython_display(width = 480)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
