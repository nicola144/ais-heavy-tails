{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import multivariate_normal, multivariate_t, random_correlation\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "import imageio\n",
    "import moviepy.editor as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save(obj, filename):\n",
    "    \"\"\"Save compiled models for reuse.\"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load(filename):\n",
    "    \"\"\"Reload compiled models for reuse.\"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_contour_lines(dist1, dist2, iteration=0):\n",
    "    # Generate a grid of points\n",
    "    x = np.linspace(-10, 10, 100)\n",
    "    y = np.linspace(-10, 10, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "\n",
    "    # Calculate the probability density for each distribution at each point on the grid\n",
    "    Z1 = dist1.pdf(positions.T)\n",
    "    Z2 = dist2.pdf(positions.T)\n",
    "\n",
    "    # Reshape the probability density values to match the grid shape\n",
    "    Z1 = Z1.reshape(X.shape)\n",
    "    Z2 = Z2.reshape(X.shape)\n",
    "\n",
    "    # Create a new figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the contour lines for the first distribution in blue color\n",
    "    ax.contour(X, Y, Z1, colors='blue', label='Proposal')\n",
    "\n",
    "    # Plot the contour lines for the second distribution in red color\n",
    "    ax.contour(X, Y, Z2, colors='red', label='Target')\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_title('Contour Lines')\n",
    "\n",
    "    # # Add a legend in the upper right corner\n",
    "    # ax.legend()\n",
    "\n",
    "    plt.savefig(\"results/ais-heavy-iter-{}.png\".format(iteration), bbox_inches=\"tight\", dpi=100)\n",
    "    # plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Given log weights, return the normalized weights\n",
    "def normalize_log(log_weights):\n",
    "\treturn np.exp(log_weights - logsumexp(log_weights)).flatten()\n",
    "\n",
    "# Given log weights, return the * log of * the normalized weights\n",
    "def log_normalize_log(log_weights):\n",
    "\treturn log_weights - logsumexp(log_weights)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load any settings\n",
    "with open(\"settings.yaml\", mode=\"r\") as file:\n",
    "    settings = yaml.safe_load(file)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "D = settings['D']\n",
    "ddof_target = settings['ddof_target']\n",
    "ddof_proposal = ddof_target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Target\n",
    "mean_target = np.zeros(D)\n",
    "std_devs_target = np.diag(np.sqrt(np.ones(D)*2))\n",
    "random_corr_mat = random_correlation(eigs=np.ones(D)).rvs(1)\n",
    "cov_target =  std_devs_target @ random_corr_mat  @ std_devs_target\n",
    "shape_target = ((ddof_target - 2) / ddof_target) * cov_target\n",
    "\n",
    "# Proposal\n",
    "mean_proposal = np.ones(D) * 0.25\n",
    "std_devs_proposal = np.diag(np.sqrt(np.ones(D)*4))\n",
    "# random_corr_mat = random_correlation(eigs= np.ones(D)).rvs(1)\n",
    "cov_proposal = std_devs_proposal @ random_corr_mat @ std_devs_proposal\n",
    "\n",
    "shape_proposal = ((ddof_proposal - 2) / ddof_proposal) * cov_proposal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AMIS(mu_initial,shape_initial, n_iterations, target_pdf, ddof_proposal, M=5000):\n",
    "    all_normalized_logweights = np.empty((n_iterations,M))\n",
    "    all_logweights = np.empty((n_iterations,M))\n",
    "    proposals_over_iterations = []\n",
    "\n",
    "    # Iteration 0\n",
    "    first_proposal = multivariate_t(loc=mu_initial,shape=shape_initial,df=ddof_proposal)\n",
    "    proposals_over_iterations.append(first_proposal)\n",
    "    samples_initial = first_proposal.rvs(size=M)\n",
    "\n",
    "    log_numerator = target_pdf.logpdf(samples_initial)\n",
    "    log_denominator = first_proposal.logpdf(samples_initial)\n",
    "\n",
    "    # assert log_numerator.shape == log_denominator.shape\n",
    "\n",
    "    all_logweights[0,:] = log_numerator - log_denominator\n",
    "    all_normalized_logweights[0,:] = log_normalize_log(log_numerator - log_denominator)\n",
    "\n",
    "    mu_current, shape_current =  np.average(samples_initial, weights=np.exp(all_normalized_logweights[0,:]), axis=0), ((ddof_target - 2) / ddof_target) * np.cov(samples_initial, rowvar=False, aweights=np.exp(all_normalized_logweights[0,:]))\n",
    "\n",
    "    # assert np.allclose( np.average(samples_initial, weights=np.exp(all_normalized_logweights[0,:]),axis=0), np.sum( np.prod( samples_initial, np.exp(all_normalized_logweights[0,:]) ) , axis=0) )\n",
    "    # assert mu_current.shape == (D,) and shape_current.shape == (D,D)\n",
    "\n",
    "    # Iteration t > 0\n",
    "    for t in tqdm(range(1,n_iterations)):\n",
    "\n",
    "        current_proposal = multivariate_t(loc=mu_current,shape=shape_current,df=ddof_proposal)\n",
    "\n",
    "        proposals_over_iterations.append(current_proposal)\n",
    "\n",
    "        # Plot current proposal vs target\n",
    "        plot_contour_lines(current_proposal,target_pdf,iteration=t)\n",
    "\n",
    "        # Draw M samples from current proposal\n",
    "        samples_current = current_proposal.rvs(size=M)\n",
    "\n",
    "        # Weighting and re-weighting procedure\n",
    "        # Numerator\n",
    "        log_numerator = target_pdf.logpdf(samples_current)\n",
    "        # Note the mixture in the denominator !\n",
    "        mixture_denominator_evaluations = np.asarray([ proposals_over_iterations[prev_t].logpdf(samples_current) for prev_t in range(0,t+1) ])\n",
    "\n",
    "        log_denominator = - np.log(t) + logsumexp( mixture_denominator_evaluations, axis=0) # check correct axis\n",
    "\n",
    "        # assert log_numerator.shape == log_denominator.shape\n",
    "\n",
    "        all_logweights[t,:] = log_numerator - log_denominator\n",
    "        all_normalized_logweights[t,:] = log_normalize_log(log_numerator - log_denominator)\n",
    "\n",
    "        # Update proposal\n",
    "        mu_current, shape_current = np.average(samples_current, weights=np.exp(all_normalized_logweights[t,:]), axis=0), ((ddof_target - 2) / ddof_target) * np.cov(samples_current, rowvar=False, aweights=np.exp(all_normalized_logweights[t,:]))\n",
    "\n",
    "#         print(mu_current - mean_target)\n",
    "#         print(shape_current - shape_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_contour_lines(multivariate_t(loc=mean_proposal,shape=shape_proposal,df=ddof_proposal), multivariate_t(loc=mean_target,shape=shape_target,df=ddof_proposal), iteration=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AMIS(mu_initial=mean_proposal,shape_initial=shape_proposal, n_iterations=150, target_pdf=multivariate_t(loc=mean_target,shape=shape_target,df=ddof_target), ddof_proposal=ddof_proposal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write movie to a file\n",
    "filenames = [os.path.join(\"results\", \"ais-heavy-iter-{}.png\".format(i)) for i in range(0,150)]\n",
    "\n",
    "with imageio.get_writer(os.path.join(\"results\", 'movie.gif'), mode='I', duration=0.3) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "clip = mp.VideoFileClip(os.path.join(\"results\", 'movie.gif'))\n",
    "clip.write_videofile(os.path.join(\"results\", 'movie.mp4'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
