{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import multivariate_normal, multivariate_t, random_correlation\n",
    "import yaml\n",
    "import os\n",
    "import imageio\n",
    "import moviepy.editor as mp\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load any settings\n",
    "with open(\"settings.yaml\", mode=\"r\") as file:\n",
    "    settings = yaml.safe_load(file)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "D = 2\n",
    "ddof_target = settings['ddof_target']\n",
    "\n",
    "ddof_proposal = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Target\n",
    "mean_target = np.zeros(D)\n",
    "std_devs_target = np.diag(np.sqrt(np.ones(D)*2))\n",
    "random_corr_mat = random_correlation(eigs=np.ones(D)).rvs(1)\n",
    "cov_target =  std_devs_target @ random_corr_mat  @ std_devs_target\n",
    "shape_target = ((ddof_target - 2) / ddof_target) * cov_target\n",
    "\n",
    "# Proposal\n",
    "mean_proposal = np.ones(D)*2\n",
    "\n",
    "std_devs_proposal = np.diag(np.sqrt(np.ones(D)*7))\n",
    "# For now same correlation as target, just different variances\n",
    "cov_proposal = std_devs_proposal @ random_corr_mat @ std_devs_proposal\n",
    "\n",
    "# The Student-t 'shape matrix' is a rescaled covariance\n",
    "shape_proposal = ((ddof_proposal - 2) / ddof_proposal) * cov_proposal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AMIS\n",
    "\n",
    "From : [https://ieeexplore.ieee.org/abstract/document/8902642?casa_token=gK_xJB2jt34AAAAA:65X9GElDk4_j4odWQmpPAp7nmEr7EXBzAFIwvgrqQdiCllmvO2ozoaF93Rs9t0tAg-2QvBEA_dw](here)\n",
    "\n",
    "Note $\\theta_j = (\\mu_j, \\Sigma_j)$\n",
    "\n",
    "For $t=1,\\dots,T$:\n",
    "\n",
    "* Draw $M$ samples from the current proposal: $x_{t}^{(m)} \\sim q(x, \\theta_t), m=1,\\dots,M$\n",
    "* Weight the samples: $w_{\\tau}^{(m)} = \\frac{\\pi(x_{\\tau}^{(m)})}{(1/t) \\sum_{j=1}^{t} q(x_{\\tau}^{(m)}; \\theta_{j})} $ for $\\tau=1,\\dots,t$ and $m=1,\\dots,M$\n",
    "* Normalize the weights: $\\bar{w}_{\\tau}^{(m)} = \\frac{w_{\\tau}^{(m)}}{\\sum_{j=1}^{t} \\sum_{m=1}^{M} w_{j}^{(m)}}$\n",
    "* Update proposal parameters:\n",
    "    * $\\mu_{t+1} = \\sum_{j=1}^{t} \\sum_{m=1}^{M} \\bar{w}_{j}^{(m)} x_{j}^{(m)}$\n",
    "    * $\\Sigma_{t+1} = \\sum_{j=1}^{t} \\sum_{m=1}^{M} \\bar{w}_{j}^{(m)}  (x_{j}^{(m)} - \\mu_{t+1})(x_{j}^{(m)} - \\mu_{t+1})^\\top $\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def AMIS_student_fixed_dof(mu_initial,shape_initial, n_iterations, target_pdf, ddof_proposal, M=200):\n",
    "    all_normalized_logweights = np.empty((n_iterations,M))\n",
    "    all_logweights = np.empty((n_iterations,M))\n",
    "    all_samples = np.empty((n_iterations,M,D))\n",
    "    evaluations_target_logpdf = np.empty((n_iterations,M))\n",
    "\n",
    "    proposals_over_iterations = []\n",
    "\n",
    "    # Iteration 0\n",
    "    first_proposal = multivariate_t(loc=mu_initial,shape=shape_initial,df=ddof_proposal)\n",
    "    proposals_over_iterations.append(first_proposal)\n",
    "    samples_initial = first_proposal.rvs(size=M)\n",
    "    all_samples[0,:] = samples_initial\n",
    "\n",
    "    log_numerator = target_pdf.logpdf(samples_initial)\n",
    "    evaluations_target_logpdf[0,:] = log_numerator\n",
    "\n",
    "    log_denominator = first_proposal.logpdf(samples_initial) # No temporal mixture in iteration 0\n",
    "\n",
    "    # assert log_numerator.shape == log_denominator.shape\n",
    "    current_logweights = log_numerator - log_denominator\n",
    "    all_logweights[0,:] = current_logweights\n",
    "    all_normalized_logweights[0,:] = current_logweights - logsumexp(current_logweights)\n",
    "\n",
    "    mu_current, shape_current = np.average(samples_initial, weights=np.exp(all_normalized_logweights[0,:]), axis=0), ((ddof_target - 2) / ddof_target) * np.cov(samples_initial, rowvar=False, aweights=np.exp(all_normalized_logweights[0,:]))\n",
    "\n",
    "    # Zero-eth iteration is working\n",
    "\n",
    "    assert mu_current.shape == (D,) and shape_current.shape == (D,D)\n",
    "\n",
    "    # Iteration t > 0\n",
    "    for t in tqdm(range(1,n_iterations)):\n",
    "\n",
    "        current_proposal = multivariate_t(loc=mu_current, shape=shape_current, df=ddof_proposal)\n",
    "\n",
    "        proposals_over_iterations.append(current_proposal)\n",
    "\n",
    "        # Plot current proposal vs target\n",
    "        plot_contour_lines(current_proposal, target_pdf, iteration=t)\n",
    "\n",
    "        # Draw M samples from current proposal\n",
    "        samples_current = current_proposal.rvs(size=M)\n",
    "        all_samples[t,:] = samples_current # this adds to the existing list of samples, does not override\n",
    "\n",
    "        # Weighting and re-weighting procedure\n",
    "\n",
    "        # Numerator\n",
    "        evaluations_target_logpdf[t,:] = target_pdf.logpdf(samples_current) # this adds to the existing list of target evaluations\n",
    "\n",
    "        log_numerator = evaluations_target_logpdf[:t+1,:] # t+1 since including current ones !\n",
    "\n",
    "        # Note the mixture in the denominator !\n",
    "\n",
    "        def temporal_mixture(x):\n",
    "            evaluations_mixture_component = np.empty((t+1,t+1,M))\n",
    "            for tau in range(0,t+1):\n",
    "                for j in range(0,t+1):\n",
    "                    evaluations_mixture_component[tau,j,:] = proposals_over_iterations[j].logpdf(x[tau,:,:])\n",
    "\n",
    "            # NOTE: Tried to vectorize as below but strangely gives different results... depends on what SciPy's .logpdf() does for 3 dimensional tensor x\n",
    "            # vectorized_evaluations_mixture_component = np.asarray([ proposals_over_iterations[prev_t].logpdf(x) for prev_t in range(0,t+1) ])\n",
    "            # assert np.allclose(vectorized_evaluations_mixture_component, evaluations_mixture_component)\n",
    "\n",
    "            return logsumexp(evaluations_mixture_component,axis=1)\n",
    "\n",
    "        mixture_denominator_evaluations = temporal_mixture(all_samples[:t+1,:,:])\n",
    "\n",
    "        log_denominator = - np.log(t+1) +  mixture_denominator_evaluations  # check correct axis\n",
    "\n",
    "        assert log_numerator.shape == log_denominator.shape\n",
    "\n",
    "        assert all_logweights[:t+1,:].shape == log_numerator.shape\n",
    "\n",
    "        updated_logweights = log_numerator - log_denominator\n",
    "        all_logweights[:t+1,:] = updated_logweights # each iteration updates all weights up to time t\n",
    "\n",
    "        updated_normalized_logweights = updated_logweights - logsumexp(updated_logweights)\n",
    "        all_normalized_logweights[:t+1,:] = updated_normalized_logweights\n",
    "\n",
    "        ### Update proposal\n",
    "        # mu_current, shape_current = np.average(samples_current, weights=np.exp(current_normalized_logweights), axis=0), ((ddof_target - 2) / ddof_target) * np.cov(samples_current, rowvar=False, aweights=np.exp(current_normalized_logweights))\n",
    "\n",
    "        samples_up_to_now = all_samples[:t+1,:,:]\n",
    "\n",
    "        ## SLOW version for debugging:\n",
    "\n",
    "        # mu_current = np.zeros(D)\n",
    "        # for tau in range(t):\n",
    "        #     for m in range(M):\n",
    "        #         mu_current += np.exp(updated_normalized_logweights[tau, m]) * samples_up_to_now[t, m, :]\n",
    "        #\n",
    "        # shape_current = np.zeros((D, D))\n",
    "        # for tau in range(t):\n",
    "        #     for m in range(M):\n",
    "        #         shape_current += np.exp(updated_normalized_logweights[tau, m]) * (samples_up_to_now[t, m, :].reshape(-1, 1) @ samples_up_to_now[t, m, :].reshape(1, -1))\n",
    "        #\n",
    "        # shape_current = ((ddof_proposal - 2) / ddof_proposal) * shape_current\n",
    "\n",
    "        #### Vectorized versions\n",
    "\n",
    "        mu_current = np.einsum('tmd,tm->d', samples_up_to_now, np.exp(updated_normalized_logweights))\n",
    "\n",
    "        diff = all_samples[:t+1,:,:] - mu_current.reshape(1, 1, D)\n",
    "\n",
    "        shape_current = ((ddof_proposal - 2) / ddof_proposal) * np.einsum('tm, tmd, tme -> de', np.exp(updated_normalized_logweights), diff, diff)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_contour_lines(multivariate_t(loc=mean_proposal,shape=shape_proposal,df=ddof_proposal), multivariate_t(loc=mean_target,shape=shape_target,df=ddof_target), iteration=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AMIS_student_fixed_dof(mu_initial=mean_proposal,shape_initial=shape_proposal, n_iterations=30, target_pdf=multivariate_t(loc=mean_target,shape=shape_target,df=ddof_target), ddof_proposal=ddof_proposal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write movie to a file\n",
    "filenames = [os.path.join(\"results\", \"ais-heavy-iter-{}.png\".format(i)) for i in range(0,150)]\n",
    "\n",
    "with imageio.get_writer(os.path.join(\"results\", 'movie.gif'), mode='I', duration=0.3) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "clip = mp.VideoFileClip(os.path.join(\"results\", 'movie.gif'))\n",
    "clip.write_videofile(os.path.join(\"results\", 'movie.mp4'))\n",
    "# showing clip\n",
    "# clip.ipython_display(width = 480)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
