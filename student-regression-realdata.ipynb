{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Example E.5.3. BAYESIAN STUDENT-T REGRESSION from https://openreview.net/pdf?id=HltJfwwfhX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pystan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import rpy2py\n",
    "import rpy2.robjects as ro\n",
    "import json\n",
    "import jax\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "from amis_algorithms import alpha_AMIS_fixed_dof, AMIS_student_fixed_dof, alpha_AMIS_adapted_dof\n",
    "\n",
    "# import bridgestan\n",
    "\n",
    "from utils import old_ksd\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "\n",
    "import pickle\n",
    "# import tikzplotlib\n",
    "\n",
    "# Enable LaTeX for nicer plotting\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "\n",
    "\n",
    "# from tueplots import bundles\n",
    "# plt.rcParams.update(bundles.aistats2023())\n",
    "\n",
    "from experiments_amis import run_AMIS_real_dataset, run_adaptiveAMISrealdataset\n",
    "\n",
    "\n",
    "# # Load and prepare the dataset\n",
    "# url = \"https://github.com/faosorios/heavy/blob/master/data/creatinine.rda?raw=true\"\n",
    "# with requests.get(url) as resp:\n",
    "#     with open(\"creatinine.rda\", \"wb\") as f:\n",
    "#         f.write(resp.content)\n",
    "\n",
    "# Load and prepare the dataset\n",
    "url = \"https://github.com/faosorios/heavy/blob/master/data/creatinine.rda?raw=true\"\n",
    "filename = \"creatinine.rda\"\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(filename):\n",
    "    with requests.get(url) as resp:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "    print(f\"{filename} downloaded.\")\n",
    "else:\n",
    "    print(f\"{filename} already exists.\")\n",
    "\n",
    "# Load RDA file into Python\n",
    "ro.r['load'](\"creatinine.rda\")\n",
    "df = pandas2ri.rpy2py_dataframe(ro.r['creatinine'])\n",
    "\n",
    "data_df = pd.DataFrame(columns=['log_SC', 'log_WT', 'log_140_minus_A', 'log_CR'])\n",
    "\n",
    "# Apply transformations following https://openreview.net/pdf?id=HltJfwwfhX\n",
    "data_df['log_SC'] = np.log(df['SC'])\n",
    "data_df['log_WT'] = np.log(df['WT'])\n",
    "data_df['log_CR'] = np.log(df['CR'])\n",
    "data_df['log_140_minus_A'] = np.log(140 - df['Age'])\n",
    "data_df = data_df.dropna() # remove any rows with NaN values after transformation\n",
    "\n",
    "# Compile the Stan model\n",
    "sm = pystan.StanModel(file=\"./student_reg_model.stan\")\n",
    "\n",
    "# Prepare data for Stan model\n",
    "data_for_stan = {\n",
    "    'N': len(data_df),\n",
    "    'x1': data_df['log_SC'].values.tolist(),\n",
    "    'x2': data_df['log_WT'].values.tolist(),\n",
    "    'x3': data_df['log_140_minus_A'].values.tolist(),\n",
    "    'y': data_df['log_CR'].values.tolist()  # response variable\n",
    "}\n",
    "\n",
    "# Save the data dictionary to a JSON file\n",
    "with open(\"student_regression_data.json\", \"w\") as f:\n",
    "    json.dump(data_for_stan, f, indent=4)\n",
    "\n",
    "\n",
    "# Fit the model and sample from the posterior using NUTS (NUTS paper: https://arxiv.org/abs/1111.4246)\n",
    "fit = sm.sampling(data=data_for_stan, iter=10, chains=1)\n",
    "mcmc_samples = fit.extract()\n",
    "\n",
    "stan = \"./student_reg_model.stan\"\n",
    "data = \"./student_regression_data.json\"\n",
    "\n",
    "# bridgestan_model = bridgestan.StanModel.from_stan_file(stan, data)\n",
    "\n",
    "true_log_pdf = fit.log_prob\n",
    "\n",
    "# Step 3: Find the MAP solution\n",
    "map_sol = sm.optimizing(data=data_for_stan)\n",
    "\n",
    "# Retrieve the values, extract the single element from each array, and convert to an ndarray\n",
    "map_sol_array = np.array([value.item() for value in map_sol.values()])\n",
    "\n",
    "# map_sol_list = list(map_sol.values())\n",
    "# log_dens_at_map, _, hessian_at_map = bridgestan_model.log_density_hessian(theta_unc=map_sol_array, propto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dim = 4 # Fixed\n",
    "dof_list = [3,4,5]\n",
    "\n",
    "######### Not used now, useful for ground truth, Laplace initialisation\n",
    "# mu_initial_proposal_laplace = map_sol_array\n",
    "#\n",
    "# assert np.isclose(log_dens_at_map, fit.log_prob(map_sol_list))\n",
    "#\n",
    "# # Negative inverse of the Hessian at the MAP solution used as covariance\n",
    "# cov_laplace = -np.linalg.inv(hessian_at_map)\n",
    "#\n",
    "# assert np.all(np.linalg.eigvals(cov_laplace) > 0)\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 25\n",
    "nb_runs = 100\n",
    "\n",
    "\n",
    "sigmaSq_init = 4\n",
    "\n",
    "# initt = 'Laplaceinit'\n",
    "initt = 'Sigmfixedinit'+str(sigmaSq_init)\n",
    "\n",
    "\n",
    "# list_num_samples = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "\n",
    "# list_num_samples = [x for x in range(5000, 10001, 500)]\n",
    "\n",
    "list_num_samples_one = [x for x in range(5000, 10001, 500)]\n",
    "list_num_samples_two = [x for x in range(500, 5000, 500)] # remaining part\n",
    "\n",
    "list_num_samples = list_num_samples_one + list_num_samples_two"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run with adaptive tail"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ADAPTIVE\n",
    "\n",
    "dof_proposal = 1\n",
    "\n",
    "for num_samples in list_num_samples:\n",
    "\n",
    "    all_est_Z, ESS, alphaESS, all_dof = run_adaptiveAMISrealdataset(alg=alpha_AMIS_adapted_dof, nb_runs=nb_runs, n_iterations=n_iter, log_pi_tilde=true_log_pdf, dof_proposal=dof_proposal, M=num_samples, d=dim, sigmaSq_init=sigmaSq_init)\n",
    "\n",
    "    print('done adaptive alpha-AMIS with n_samples', num_samples)\n",
    "\n",
    "\n",
    "    np.save('./results/realdata/all_replicates/adaptiveGPadaptivealphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_allestZ.npy\", all_est_Z)\n",
    "    np.save('./results/realdata/all_replicates/adaptiveGPadaptivealphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_ESS.npy\", ESS)\n",
    "    np.save('./results/realdata/all_replicates/adaptiveGPadaptivealphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_alphaESS.npy\", alphaESS)\n",
    "    np.save('./results/realdata/all_replicates/adaptiveGPadaptivealphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_alldof.npy\", all_dof)\n",
    "\n",
    "    del all_est_Z, ESS, alphaESS, all_dof\n",
    "\n",
    "    # if done_AMIS:\n",
    "    #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_meanZ_baseline.npy\", mean_Z_baseline)\n",
    "    #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_stdZ_baseline.npy\", std_Z_baseline)\n",
    "    #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_ESS_baseline.npy\", mean_ESS_baseline)\n",
    "    #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_ESS_baseline.npy\", std_ESS_baseline)\n",
    "    #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_alphaESS_baseline.npy\", mean_alphaESS_baseline)\n",
    "    #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_alphaESS_baseline.npy\", std_alphaESS_baseline)\n",
    "    #\n",
    "    #     del mean_Z_baseline,std_Z_baseline,mean_ESS_baseline,std_ESS_baseline,mean_alphaESS_baseline,std_alphaESS_baseline\n",
    "    #\n",
    "    # if done_alphaAMIS:\n",
    "    #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_Z.npy\", mean_Z)\n",
    "    #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_Z.npy\", std_Z)\n",
    "    #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_ESS.npy\", mean_ESS)\n",
    "    #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_ESS.npy\", std_ESS)\n",
    "    #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_alphaESS.npy\", mean_alphaESS)\n",
    "    #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_alphaESS.npy\", std_alphaESS)\n",
    "    #\n",
    "    #     del mean_Z,std_Z,mean_ESS,std_ESS,mean_alphaESS,std_alphaESS\n",
    "\n",
    "    gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run AMIS and fixed dof alphaAMIS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FIXED DOF\n",
    "for dof_proposal in dof_list:\n",
    "\n",
    "\n",
    "    for num_samples in list_num_samples:\n",
    "\n",
    "        done_AMIS = False\n",
    "        done_alphaAMIS = False\n",
    "\n",
    "        # if not os.path.exists('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_meanZ_baseline.npy\"):\n",
    "\n",
    "        all_est_Z_baseline, ESS_baseline, alphaESS_baseline  = run_AMIS_real_dataset(alg=AMIS_student_fixed_dof, nb_runs=nb_runs, n_iterations=n_iter, log_pi_tilde=true_log_pdf, dof_proposal=dof_proposal, M=num_samples, d=dim, sigmaSq_init=sigmaSq_init)\n",
    "\n",
    "        print('done AMIS with n_samples', num_samples)\n",
    "            # done_AMIS = True\n",
    "\n",
    "        # if not os.path.exists('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_Z.npy\"):\n",
    "\n",
    "        all_est_Z, ESS, alphaESS = run_AMIS_real_dataset(alg=alpha_AMIS_fixed_dof, nb_runs=nb_runs, n_iterations=n_iter, log_pi_tilde=true_log_pdf, dof_proposal=dof_proposal, M=num_samples, d=dim, sigmaSq_init=sigmaSq_init)\n",
    "\n",
    "        print('done alpha-AMIS with n_samples', num_samples)\n",
    "\n",
    "            # done_alphaAMIS = True\n",
    "\n",
    "        np.save('./results/realdata/all_replicates/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_allestZ_baseline.npy\", all_est_Z_baseline)\n",
    "        np.save('./results/realdata/all_replicates/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_ESS_baseline.npy\", ESS_baseline)\n",
    "        np.save('./results/realdata/all_replicates/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_alphaESS_baseline.npy\", alphaESS_baseline)\n",
    "\n",
    "        np.save('./results/realdata/all_replicates/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_allestZ.npy\", all_est_Z)\n",
    "        np.save('./results/realdata/all_replicates/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_ESS.npy\", ESS)\n",
    "        np.save('./results/realdata/all_replicates/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_alphaESS.npy\", alphaESS)\n",
    "\n",
    "        del all_est_Z_baseline, ESS_baseline, alphaESS_baseline, all_est_Z, ESS, alphaESS\n",
    "\n",
    "        # if done_AMIS:\n",
    "        #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_meanZ_baseline.npy\", mean_Z_baseline)\n",
    "        #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_stdZ_baseline.npy\", std_Z_baseline)\n",
    "        #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_ESS_baseline.npy\", mean_ESS_baseline)\n",
    "        #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_ESS_baseline.npy\", std_ESS_baseline)\n",
    "        #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_alphaESS_baseline.npy\", mean_alphaESS_baseline)\n",
    "        #     np.save('./results/realdata/AMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_alphaESS_baseline.npy\", std_alphaESS_baseline)\n",
    "        #\n",
    "        #     del mean_Z_baseline,std_Z_baseline,mean_ESS_baseline,std_ESS_baseline,mean_alphaESS_baseline,std_alphaESS_baseline\n",
    "        #\n",
    "        # if done_alphaAMIS:\n",
    "        #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_Z.npy\", mean_Z)\n",
    "        #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_Z.npy\", std_Z)\n",
    "        #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_ESS.npy\", mean_ESS)\n",
    "        #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_ESS.npy\", std_ESS)\n",
    "        #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_mean_alphaESS.npy\", mean_alphaESS)\n",
    "        #     np.save('./results/realdata/alphaAMIS/' + initt + \"_\" + str(num_samples) + \"_dof_\" + str(dof_proposal) + \"_nbruns_\" + str(nb_runs) + \"_niter_\" + str(n_iter) + \"_std_alphaESS.npy\", std_alphaESS)\n",
    "        #\n",
    "        #     del mean_Z,std_Z,mean_ESS,std_ESS,mean_alphaESS,std_alphaESS\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    # Last key is the log probability, which we don't want\n",
    "    # exclude_key = \"lp__\"\n",
    "    # mcmc_samples = OrderedDict((k, v) for k, v in mcmc_samples.items() if k != exclude_key)\n",
    "    # mcmc_samples_array = np.vstack(list(mcmc_samples.values())).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading data for plotting\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load\n",
    "def load_all_npy_files(directory):\n",
    "    \"\"\"\n",
    "    Load all .npy files from a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory containing .npy files.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with filenames as keys and loaded numpy arrays as values.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.npy')]\n",
    "    data = {}\n",
    "\n",
    "    for f in files:\n",
    "        full_path = os.path.join(directory, f)\n",
    "        data[f] = np.load(full_path)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Usage\n",
    "directory_path = './results/realdata/all_replicates/AMIS'\n",
    "loaded_data = load_all_npy_files(directory_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "directory_path_alphaAMIS = './results/realdata/all_replicates/alphaAMIS/'\n",
    "loaded_data_alphaAMIS = load_all_npy_files(directory_path_alphaAMIS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "directory_path_adaptivealphaAMIS = './results/realdata/all_replicates/adaptiveGPadaptivealphaAMIS/'\n",
    "loaded_data_adaptivealphaAMIS = load_all_npy_files(directory_path_adaptivealphaAMIS)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictionaries_data = [loaded_data, loaded_data_alphaAMIS, loaded_data_adaptivealphaAMIS]\n",
    "\n",
    "set_keys_metrics, set_dofs, set_initialisation, set_nbruns, set_numsamples = set(), set(), set(), set(), set()\n",
    "\n",
    "# First create dict\n",
    "for i, data in enumerate(dictionaries_data):\n",
    "    for key, _ in data.items():\n",
    "\n",
    "        parts = key.replace(\".npy\", \"\").split(\"_\")\n",
    "        cleaned_parts = list(filter(lambda item: item != '', parts))\n",
    "\n",
    "        # print(cleaned_parts)\n",
    "\n",
    "        initialisation = cleaned_parts[0]\n",
    "        numsamples = cleaned_parts[1]\n",
    "        metric = cleaned_parts[-1] if (i==1) or (i ==2) else cleaned_parts[-2]\n",
    "\n",
    "        # if metric == 'alldof':\n",
    "        #     continue\n",
    "\n",
    "        dof = cleaned_parts[3]\n",
    "        nbruns = cleaned_parts[5]\n",
    "\n",
    "        set_keys_metrics.add(metric)\n",
    "        set_dofs.add(dof)\n",
    "        set_initialisation.add(initialisation)\n",
    "        set_numsamples.add(numsamples)\n",
    "        set_nbruns.add(nbruns)\n",
    "\n",
    "results_final_baseline, results_final_ours, results_final_ours_adapted = {}, {}, {}\n",
    "\n",
    "set_keys_metrics_no_dofs = set_keys_metrics.copy()\n",
    "set_keys_metrics_no_dofs.remove('alldof')\n",
    "\n",
    "for metric in set_keys_metrics_no_dofs:\n",
    "    results_final_baseline[metric], results_final_ours[metric] = {}, {}\n",
    "    for initt in set_initialisation:\n",
    "        results_final_baseline[metric][initt], results_final_ours[metric][initt] = {}, {}\n",
    "        for dof in set_dofs:\n",
    "            results_final_baseline[metric][initt][dof], results_final_ours[metric][initt][dof] = {}, {}\n",
    "            for nbruns in set_nbruns:\n",
    "                results_final_baseline[metric][initt][dof][nbruns], results_final_ours[metric][initt][dof][nbruns] = {}, {}\n",
    "                for numsamples in set_numsamples:\n",
    "                    results_final_baseline[metric][initt][dof][nbruns][numsamples], results_final_ours[metric][initt][dof][nbruns][numsamples]= None, None\n",
    "\n",
    "for metric in set_keys_metrics:\n",
    "    results_final_ours_adapted[metric] = {}\n",
    "    for initt in set_initialisation:\n",
    "        results_final_ours_adapted[metric][initt] = {}\n",
    "        for dof in set_dofs:\n",
    "            results_final_ours_adapted[metric][initt][dof] = {}\n",
    "            for nbruns in set_nbruns:\n",
    "                results_final_ours_adapted[metric][initt][dof][nbruns] = {}\n",
    "                for numsamples in set_numsamples:\n",
    "                    results_final_ours_adapted[metric][initt][dof][nbruns][numsamples] = None\n",
    "\n",
    "for i, data in enumerate(dictionaries_data):\n",
    "    for key, value in data.items():\n",
    "\n",
    "        parts = key.replace(\".npy\", \"\").split(\"_\")\n",
    "        cleaned_parts = list(filter(lambda item: item != '', parts))\n",
    "\n",
    "        initialisation = cleaned_parts[0]\n",
    "        numsamples = cleaned_parts[1]\n",
    "        metric = cleaned_parts[-1] if (i==1) or (i ==2) else cleaned_parts[-2]\n",
    "\n",
    "        dof = cleaned_parts[3]\n",
    "        nbruns = cleaned_parts[5]\n",
    "\n",
    "        if i == 0:\n",
    "            results_final_baseline[metric][initialisation][dof][nbruns][numsamples] = value\n",
    "        elif i == 1:\n",
    "            results_final_ours[metric][initialisation][dof][nbruns][numsamples] = value\n",
    "        else: # i == 2\n",
    "            results_final_ours_adapted[metric][initialisation][dof][nbruns][numsamples] = value\n",
    "\n",
    "\n",
    "# # Cleaning for old data\n",
    "# # First create dict\n",
    "# for i, data in enumerate(dictionaries_data):\n",
    "#     for key, _ in data.items():\n",
    "#\n",
    "#         parts = key.replace(\".npy\", \"\").replace(\"niter\",\"\").replace(\"25\",\"\").split(\"_\")\n",
    "#         cleaned_parts = list(filter(lambda item: item != '', parts))\n",
    "#\n",
    "#         # Cleaning\n",
    "#         if 'ESS' in cleaned_parts:\n",
    "#             idx = cleaned_parts.index('ESS')\n",
    "#             cleaned_parts[idx-1]+= 'ESS'\n",
    "#             cleaned_parts.remove('ESS')\n",
    "#         if 'alphaESS' in cleaned_parts:\n",
    "#             idx = cleaned_parts.index('alphaESS')\n",
    "#             cleaned_parts[idx-1]+= 'alphaESS'\n",
    "#             cleaned_parts.remove('alphaESS')\n",
    "#         if 'Z' in cleaned_parts:\n",
    "#             idx = cleaned_parts.index('Z')\n",
    "#             cleaned_parts[idx-1]+= 'Z'\n",
    "#             cleaned_parts.remove('Z')\n",
    "#\n",
    "#         initialisation = cleaned_parts[0]\n",
    "#         numsamples = cleaned_parts[1]\n",
    "#         metric = cleaned_parts[-1] if i==1 else cleaned_parts[-2]\n",
    "#         dof = cleaned_parts[3]\n",
    "#         nbruns = cleaned_parts[5]\n",
    "#\n",
    "#         set_keys_metrics.add(metric)\n",
    "#         set_dofs.add(dof)\n",
    "#         set_initialisation.add(initialisation)\n",
    "#         set_numsamples.add(numsamples)\n",
    "#         set_nbruns.add(nbruns)\n",
    "#\n",
    "# results_final_baseline, results_final_ours= {}, {}\n",
    "#\n",
    "# for metric in set_keys_metrics:\n",
    "#     results_final_baseline[metric], results_final_ours[metric] = {}, {}\n",
    "#     for initt in set_initialisation:\n",
    "#         results_final_baseline[metric][initt], results_final_ours[metric][initt] = {}, {}\n",
    "#         for dof in set_dofs:\n",
    "#             results_final_baseline[metric][initt][dof], results_final_ours[metric][initt][dof] = {}, {}\n",
    "#             for nbruns in set_nbruns:\n",
    "#                 results_final_baseline[metric][initt][dof][nbruns], results_final_ours[metric][initt][dof][nbruns] = {}, {}\n",
    "#                 for numsamples in set_numsamples:\n",
    "#                     results_final_baseline[metric][initt][dof][nbruns][numsamples], results_final_ours[metric][initt][dof][nbruns][numsamples] = [], []\n",
    "#\n",
    "# for i, data in enumerate(dictionaries_data):\n",
    "#     for key, value in data.items():\n",
    "#\n",
    "#         parts = key.replace(\".npy\", \"\").replace(\"niter\",\"\").replace(\"25\",\"\").split(\"_\")\n",
    "#         cleaned_parts = list(filter(lambda item: item != '', parts))\n",
    "#\n",
    "#         # Cleaning\n",
    "#         if 'ESS' in cleaned_parts:\n",
    "#             idx = cleaned_parts.index('ESS')\n",
    "#             cleaned_parts[idx-1]+= 'ESS'\n",
    "#             cleaned_parts.remove('ESS')\n",
    "#         if 'alphaESS' in cleaned_parts:\n",
    "#             idx = cleaned_parts.index('alphaESS')\n",
    "#             cleaned_parts[idx-1]+= 'alphaESS'\n",
    "#             cleaned_parts.remove('alphaESS')\n",
    "#         if 'Z' in cleaned_parts:\n",
    "#             idx = cleaned_parts.index('Z')\n",
    "#             cleaned_parts[idx-1]+= 'Z'\n",
    "#             cleaned_parts.remove('Z')\n",
    "#\n",
    "#         initialisation = cleaned_parts[0]\n",
    "#         numsamples = cleaned_parts[1]\n",
    "#         metric = cleaned_parts[-1] if i==1 else cleaned_parts[-2]\n",
    "#         dof = cleaned_parts[3]\n",
    "#         nbruns = cleaned_parts[5]\n",
    "#\n",
    "#         if not value.shape == ():\n",
    "#             value = value[-1] # keeping only last value of iteration number\n",
    "#\n",
    "#         if i == 0:\n",
    "#             # print(value)\n",
    "#             # print(value.item())\n",
    "#             # print(value.shape)\n",
    "#             results_final_baseline[metric][initialisation][dof][nbruns][numsamples].append(value.item())\n",
    "#         else: #(i == 1)\n",
    "#             results_final_ours[metric][initialisation][dof][nbruns][numsamples].append(value.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DOF evolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_numsamples = sorted(\n",
    "    [\n",
    "        int(key)\n",
    "        for key, value in results_final_ours_adapted['alldof']['Sigmfixedinit4']['1']['100'].items()\n",
    "        if value is not None\n",
    "    ]\n",
    ")\n",
    "sorted_numsamples_str = [str(num) for num in sorted_numsamples]\n",
    "\n",
    "# sorted_values = []\n",
    "for key in sorted_numsamples_str:\n",
    "    mean_value = results_final_ours_adapted['alldof']['Sigmfixedinit4']['1']['100'][key].mean(0)\n",
    "    std_value = results_final_ours_adapted['alldof']['Sigmfixedinit4']['1']['100'][key].std(0)\n",
    "    # sorted_values.append(mean_value)\n",
    "\n",
    "    plt.title('Dof evolution with n samples' + key)\n",
    "    plt.plot(np.arange(len(mean_value)), mean_value, label='mean')\n",
    "    plt.fill_between(np.arange(len(mean_value)), mean_value - 1.96 * std_value, mean_value + 1.96 * std_value, alpha=0.1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# sorted_values = np.asarray(sorted_values)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alpha ESS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "for dof in set_dofs:\n",
    "\n",
    "    sorted_numsamples_baseline = sorted(\n",
    "        [\n",
    "            int(key)\n",
    "            for key, value in results_final_baseline['alphaESS']['Sigmfixedinit4'][dof]['100'].items()\n",
    "            if value is not None\n",
    "        ]\n",
    "    )\n",
    "    sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "\n",
    "    # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "    # all_replicates_baseline = np.asarray([ results_final_baseline['alphaESS']['Sigmfixedinit4'][dof]['100'][key].mean() for key in sorted_numsamples_baseline_str])\n",
    "    sorted_values_baseline = []\n",
    "    for key in sorted_numsamples_baseline_str:\n",
    "            mean_value = results_final_baseline['alphaESS']['Sigmfixedinit4'][dof]['100'][key][:,-1].mean()\n",
    "            sorted_values_baseline.append(mean_value)\n",
    "\n",
    "    sorted_values_baseline = np.asarray(sorted_values_baseline)\n",
    "\n",
    "    sorted_values_baseline_std = []\n",
    "    for key in sorted_numsamples_baseline_str:\n",
    "            std_val = results_final_baseline['alphaESS']['Sigmfixedinit4'][dof]['100'][key][:,-1].std()\n",
    "            sorted_values_baseline_std.append(std_val)\n",
    "\n",
    "    sorted_values_baseline_std = np.asarray(sorted_values_baseline_std)\n",
    "\n",
    "\n",
    "\n",
    "    sorted_numsamples_ours = sorted(\n",
    "        [\n",
    "            int(key)\n",
    "            for key, value in results_final_ours['alphaESS']['Sigmfixedinit4'][dof]['100'].items()\n",
    "            if value is not None\n",
    "        ]\n",
    "    )\n",
    "    sorted_numsamples_ours_str = [str(num) for num in sorted_numsamples_ours]\n",
    "\n",
    "    # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "\n",
    "    sorted_values_ours = []\n",
    "    for key in sorted_numsamples_ours_str:\n",
    "            mean_value = results_final_ours['alphaESS']['Sigmfixedinit4'][dof]['100'][key][:,-1].mean()\n",
    "            sorted_values_ours.append(mean_value)\n",
    "\n",
    "    sorted_values_ours = np.asarray(sorted_values_ours)\n",
    "\n",
    "    sorted_values_ours_std = []\n",
    "    for key in sorted_numsamples_ours_str:\n",
    "            std_val = results_final_ours['alphaESS']['Sigmfixedinit4'][dof]['100'][key][:,-1].std()\n",
    "            sorted_values_ours_std.append(std_val)\n",
    "\n",
    "    sorted_values_ours_std = np.asarray(sorted_values_ours_std)\n",
    "\n",
    "    if dof == '3':\n",
    "        marker = 'o'\n",
    "    elif dof == '4':\n",
    "        marker = 'x'\n",
    "    else:\n",
    "        marker = 's'\n",
    "\n",
    "    plt.plot(sorted_numsamples_baseline,  sorted_values_baseline,  marker=marker, linestyle='--', label=r'AMIS $(\\nu={})$'.format(dof))\n",
    "    plt.plot(sorted_numsamples_ours,  sorted_values_ours, marker=marker, linestyle='-', label=r'escort AMIS  $(\\nu={})$'.format(dof))\n",
    "\n",
    "    plt.fill_between(sorted_numsamples_baseline, sorted_values_baseline - 1.96 * sorted_values_baseline_std, sorted_values_baseline + 1.96 * sorted_values_baseline_std, alpha=0.1)\n",
    "    plt.fill_between(sorted_numsamples_ours, sorted_values_ours - 1.96 * sorted_values_ours_std, sorted_values_ours + 1.96 * sorted_values_ours_std, alpha=0.1)\n",
    "\n",
    "\n",
    "# Adapted dof (recall it is stored in a fixed dof = 3 for now)\n",
    "sorted_numsamples_ours_adapted = sorted(\n",
    "    [\n",
    "        int(key)\n",
    "        for key, value in results_final_ours_adapted['alphaESS']['Sigmfixedinit4']['3']['100'].items()\n",
    "        if value is not None\n",
    "    ]\n",
    ")\n",
    "\n",
    "sorted_numsamples_ours_adapted_str = [str(num) for num in sorted_numsamples_ours_adapted]\n",
    "\n",
    "# Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "\n",
    "sorted_values_ours_adapted = []\n",
    "for key in sorted_numsamples_ours_adapted_str:\n",
    "        mean_value = results_final_ours_adapted['alphaESS']['Sigmfixedinit4']['3']['100'][key][:,-1].mean()\n",
    "        sorted_values_ours_adapted.append(mean_value)\n",
    "\n",
    "sorted_values_ours_adapted = np.asarray(sorted_values_ours_adapted)\n",
    "\n",
    "sorted_values_ours_adapted_std = []\n",
    "for key in sorted_numsamples_ours_adapted_str:\n",
    "        std_val = results_final_ours_adapted['alphaESS']['Sigmfixedinit4']['3']['100'][key][:,-1].std()\n",
    "        sorted_values_ours_adapted_std.append(std_val)\n",
    "\n",
    "sorted_values_ours_adapted_std = np.asarray(sorted_values_ours_adapted_std)\n",
    "\n",
    "plt.plot(sorted_numsamples_ours_adapted,  sorted_values_ours_adapted,  marker='D', linestyle='-.', label='adaptive escort AMIS ')\n",
    "\n",
    "plt.fill_between(sorted_numsamples_ours_adapted, sorted_values_ours_adapted - 1.96 * sorted_values_ours_adapted_std, sorted_values_ours_adapted + 1.96 * sorted_values_ours_adapted_std, alpha=0.1)\n",
    "\n",
    "# Access the current Axes instance:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Using MultipleLocator to place a tick every 0.5 units\n",
    "ax.xaxis.set_major_locator(MultipleLocator(500))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel(r'$\\alpha$-ESS')\n",
    "# plt.axhline(y=truth, color='r', linestyle='solid', lw=2, label=r'AMIS with $10^5$ samples (dof=5)')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('./results/creatinine_alphaESS.pdf',bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NOT ready from here onwards"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "for dof in set_dofs:\n",
    "\n",
    "    sorted_numsamples_baseline = sorted(\n",
    "        [\n",
    "            int(key)\n",
    "            for key, value in results_final_baseline['ESS']['Sigmfixedinit4'][dof]['100'].items()\n",
    "            if value is not None\n",
    "        ]\n",
    "    )\n",
    "    sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "\n",
    "    # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "    # all_replicates_baseline = np.asarray([ results_final_baseline['alphaESS']['Sigmfixedinit4'][dof]['500'][key].mean() for key in sorted_numsamples_baseline_str])\n",
    "    sorted_values_baseline = []\n",
    "    for key in sorted_numsamples_baseline_str:\n",
    "            mean_value = results_final_baseline['ESS']['Sigmfixedinit4'][dof]['500'][key][:,-1].mean()\n",
    "            sorted_values_baseline.append(mean_value)\n",
    "\n",
    "    sorted_values_baseline = np.asarray(sorted_values_baseline)\n",
    "\n",
    "    sorted_values_baseline_std = []\n",
    "    for key in sorted_numsamples_baseline_str:\n",
    "            std_val = results_final_baseline['ESS']['Sigmfixedinit4'][dof]['500'][key][:,-1].std()\n",
    "            sorted_values_baseline_std.append(std_val)\n",
    "\n",
    "    sorted_values_baseline_std = np.asarray(sorted_values_baseline_std)\n",
    "\n",
    "\n",
    "\n",
    "    sorted_numsamples_ours = sorted(\n",
    "        [\n",
    "            int(key)\n",
    "            for key, value in results_final_ours['ESS']['Sigmfixedinit4'][dof]['500'].items()\n",
    "            if value is not None\n",
    "        ]\n",
    "    )\n",
    "    sorted_numsamples_ours_str = [str(num) for num in sorted_numsamples_ours]\n",
    "\n",
    "    # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "\n",
    "    sorted_values_ours = []\n",
    "    for key in sorted_numsamples_ours_str:\n",
    "            mean_value = results_final_ours['ESS']['Sigmfixedinit4'][dof]['500'][key][:,-1].mean()\n",
    "            sorted_values_ours.append(mean_value)\n",
    "\n",
    "    sorted_values_ours = np.asarray(sorted_values_ours)\n",
    "\n",
    "    sorted_values_ours_std = []\n",
    "    for key in sorted_numsamples_ours_str:\n",
    "            std_val = results_final_ours['ESS']['Sigmfixedinit4'][dof]['500'][key][:,-1].std()\n",
    "            sorted_values_ours_std.append(std_val)\n",
    "\n",
    "    sorted_values_ours_std = np.asarray(sorted_values_ours_std)\n",
    "\n",
    "    if dof == '3':\n",
    "        marker = 'o'\n",
    "    elif dof == '4':\n",
    "        marker = 'x'\n",
    "    else:\n",
    "        marker = 's'\n",
    "\n",
    "    plt.plot(sorted_numsamples_baseline,  sorted_values_baseline,  marker=marker, linestyle='--', label=r'AMIS $(\\nu={})$'.format(dof))\n",
    "    plt.plot(sorted_numsamples_ours,  sorted_values_ours, marker=marker, linestyle='-', label=r'escort AMIS  $(\\nu={})$'.format(dof))\n",
    "\n",
    "    plt.fill_between(sorted_numsamples_baseline, sorted_values_baseline - 1.96 * sorted_values_baseline_std, sorted_values_baseline + 1.96 * sorted_values_baseline_std, alpha=0.1)\n",
    "    plt.fill_between(sorted_numsamples_ours, sorted_values_ours - 1.96 * sorted_values_ours_std, sorted_values_ours + 1.96 * sorted_values_ours_std, alpha=0.1)\n",
    "\n",
    "\n",
    "# Adapted dof (recall it is stored in a fixed dof = 3 for now)\n",
    "sorted_numsamples_ours_adapted = sorted(\n",
    "    [\n",
    "        int(key)\n",
    "        for key, value in results_final_ours_adapted['ESS']['Sigmfixedinit4']['3']['500'].items()\n",
    "        if value is not None\n",
    "    ]\n",
    ")\n",
    "\n",
    "sorted_numsamples_ours_adapted_str = [str(num) for num in sorted_numsamples_ours_adapted]\n",
    "\n",
    "# Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "\n",
    "sorted_values_ours_adapted = []\n",
    "for key in sorted_numsamples_ours_adapted_str:\n",
    "        mean_value = results_final_ours_adapted['ESS']['Sigmfixedinit4']['3']['500'][key][:,-1].mean()\n",
    "        sorted_values_ours_adapted.append(mean_value)\n",
    "\n",
    "sorted_values_ours_adapted = np.asarray(sorted_values_ours_adapted)\n",
    "\n",
    "sorted_values_ours_adapted_std = []\n",
    "for key in sorted_numsamples_ours_adapted_str:\n",
    "        std_val = results_final_ours_adapted['ESS']['Sigmfixedinit4']['3']['500'][key][:,-1].std()\n",
    "        sorted_values_ours_adapted_std.append(std_val)\n",
    "\n",
    "sorted_values_ours_adapted_std = np.asarray(sorted_values_ours_adapted_std)\n",
    "\n",
    "plt.plot(sorted_numsamples_ours_adapted,  sorted_values_ours_adapted,  marker='D', linestyle='-.', label='adaptive escort AMIS ')\n",
    "\n",
    "plt.fill_between(sorted_numsamples_ours_adapted, sorted_values_ours_adapted - 1.96 * sorted_values_ours_adapted_std, sorted_values_ours_adapted + 1.96 * sorted_values_ours_adapted_std, alpha=0.1)\n",
    "\n",
    "# Access the current Axes instance:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Using MultipleLocator to place a tick every 0.5 units\n",
    "ax.xaxis.set_major_locator(MultipleLocator(500))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel(r'ESS')\n",
    "# plt.axhline(y=truth, color='r', linestyle='solid', lw=2, label=r'AMIS with $10^5$ samples (dof=5)')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('./results/creatinine_ESS.pdf',bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dof in set_dofs:\n",
    "\n",
    "    sorted_numsamples_baseline = sorted(list(map(int, results_final_baseline['meanZ']['Laplaceinit'][dof]['20000'].keys() )))\n",
    "\n",
    "    # Best DOF it seems\n",
    "    if dof == '5':\n",
    "        truth_key = str(sorted_numsamples_baseline[-1])\n",
    "        truth = results_final_baseline['meanZ']['Laplaceinit'][dof]['1000'][truth_key][0]\n",
    "\n",
    "    sorted_numsamples_baseline = [x for x in sorted_numsamples_baseline if x in [50, 100, 150, 200, 250]]\n",
    "\n",
    "    sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "\n",
    "    # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "    sorted_values_baseline = [ results_final_baseline['meanZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_baseline_str]\n",
    "    sorted_values_baseline_std = [ results_final_baseline['stdZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_baseline_str]\n",
    "\n",
    "\n",
    "    sorted_numsamples_ours = sorted(list(map(int, results_final_ours['meanZ']['Laplaceinit'][dof]['20000'].keys() )))\n",
    "    sorted_numsamples_ours = [x for x in sorted_numsamples_ours if x in [50, 100, 150, 200, 250]]\n",
    "\n",
    "    sorted_numsamples_str = [str(num) for num in sorted_numsamples_ours] # should be the same as baseline right ?\n",
    "\n",
    "    # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "    sorted_values_ours = [ results_final_ours['meanZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_str]\n",
    "    sorted_values_ours_std = [ results_final_ours['stdZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_str]\n",
    "\n",
    "\n",
    "    sorted_values_baseline, sorted_values_ours, sorted_values_baseline_std, sorted_values_ours_std = np.array(sorted_values_baseline), np.array(sorted_values_ours), np.array(sorted_values_baseline_std), np.array(sorted_values_ours_std)\n",
    "\n",
    "    if dof == '5':\n",
    "        plt.plot(sorted_numsamples_baseline,  sorted_values_baseline, label='AMIS (\\nu={})'.format(dof))\n",
    "        plt.plot(sorted_numsamples_ours,  sorted_values_ours, label='escort AMIS  (\\nu={})'.format(dof))\n",
    "\n",
    "        plt.fill_between(sorted_numsamples_baseline, sorted_values_baseline -   sorted_values_baseline_std, sorted_values_baseline +   sorted_values_baseline_std, alpha=0.1)\n",
    "        plt.fill_between(sorted_numsamples_ours, sorted_values_ours -   sorted_values_ours_std, sorted_values_ours +   sorted_values_ours_std, alpha=0.1)\n",
    "\n",
    "plt.axhline(y=truth, color='r', linestyle='solid', lw=2, label='Estimated true value (with $10^5$ samples)')\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel(r'$\\hat{Z} value$')\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig('./results/creatinine_meanZ.pdf',bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for dof in set_dofs:\n",
    "#\n",
    "#     sorted_numsamples_baseline = sorted(list(map(int, results_final_baseline['meanalphaESS']['Laplaceinit'][dof]['20000'].keys() )))\n",
    "#\n",
    "#     # sorted_numsamples_baseline = [x for x in sorted_numsamples_baseline if x in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]]\n",
    "#\n",
    "#     sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "#\n",
    "#     # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "#     sorted_values_baseline = [ results_final_baseline['meanalphaESS']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_baseline_str]\n",
    "#     sorted_values_baseline_std = [ results_final_baseline['stdalphaESS']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_baseline_str]\n",
    "#\n",
    "#\n",
    "#     sorted_numsamples_ours = sorted(list(map(int, results_final_ours['meanalphaESS']['Laplaceinit'][dof]['20000'].keys() )))\n",
    "#     sorted_numsamples_ours = [x for x in sorted_numsamples_ours if x in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]]\n",
    "#\n",
    "#     sorted_numsamples_str = [str(num) for num in sorted_numsamples_ours] # should be the same as baseline right ?\n",
    "#\n",
    "#     # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "#     sorted_values_ours = [ results_final_ours['meanalphaESS']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_str]\n",
    "#     sorted_values_ours_std = [ results_final_ours['stdalphaESS']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_str]\n",
    "#\n",
    "#\n",
    "#     sorted_values_baseline, sorted_values_ours, sorted_values_baseline_std, sorted_values_ours_std = np.array(sorted_values_baseline), np.array(sorted_values_ours), np.array(sorted_values_baseline_std), np.array(sorted_values_ours_std)\n",
    "#\n",
    "#     plt.plot(sorted_numsamples_baseline,  sorted_values_baseline, label='AMIS (\\nu={})'.format(dof))\n",
    "#     plt.plot(sorted_numsamples_ours,  sorted_values_ours, label='escort AMIS  (\\nu={})'.format(dof))\n",
    "#\n",
    "#     plt.fill_between(sorted_numsamples_baseline, sorted_values_baseline - 1.96 * sorted_values_baseline_std, sorted_values_baseline + 1.96 * sorted_values_baseline_std, alpha=0.1)\n",
    "#     plt.fill_between(sorted_numsamples_ours, sorted_values_ours - 1.96 * sorted_values_ours_std, sorted_values_ours + 1.96 * sorted_values_ours_std, alpha=0.1)\n",
    "#\n",
    "# plt.xlabel('Number of samples')\n",
    "# plt.ylabel('alphaESS')\n",
    "# # plt.axhline(y=truth, color='r', linestyle='solid', lw=2, label=r'AMIS with $10^5$ samples (dof=5)')\n",
    "# plt.tight_layout()\n",
    "# plt.legend()\n",
    "# plt.yscale('log')\n",
    "# plt.savefig('./results/creatinine_alphaESS.pdf',bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for dof in set_dofs:\n",
    "#\n",
    "#     sorted_numsamples_baseline = sorted(list(map(int, results_final_baseline['meanZ']['Laplaceinit'][dof]['20000'].keys() )))\n",
    "#\n",
    "#     # Best DOF it seems\n",
    "#     if dof == '5':\n",
    "#         truth_key = str(sorted_numsamples_baseline[-1])\n",
    "#         truth = results_final_baseline['meanZ']['Laplaceinit'][dof]['1000'][truth_key][0]\n",
    "#\n",
    "#     sorted_numsamples_baseline = [x for x in sorted_numsamples_baseline if x in [50, 100, 150, 200, 250]]\n",
    "#\n",
    "#     sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "#\n",
    "#     # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "#     sorted_values_baseline = [ results_final_baseline['meanZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_baseline_str]\n",
    "#     sorted_values_baseline_std = [ results_final_baseline['stdZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_baseline_str]\n",
    "#\n",
    "#\n",
    "#     sorted_numsamples_ours = sorted(list(map(int, results_final_ours['meanZ']['Laplaceinit'][dof]['20000'].keys() )))\n",
    "#     sorted_numsamples_ours = [x for x in sorted_numsamples_ours if x in [50, 100, 150, 200, 250]]\n",
    "#\n",
    "#     sorted_numsamples_str = [str(num) for num in sorted_numsamples_ours] # should be the same as baseline right ?\n",
    "#\n",
    "#     # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "#     sorted_values_ours = [ results_final_ours['meanZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_str]\n",
    "#     sorted_values_ours_std = [ results_final_ours['stdZ']['Laplaceinit'][dof]['20000'][key][0] for key in sorted_numsamples_str]\n",
    "#\n",
    "#\n",
    "#     sorted_values_baseline, sorted_values_ours, sorted_values_baseline_std, sorted_values_ours_std = np.array(sorted_values_baseline), np.array(sorted_values_ours), np.array(sorted_values_baseline_std), np.array(sorted_values_ours_std)\n",
    "#\n",
    "#     if dof == '5':\n",
    "#         plt.plot(sorted_numsamples_baseline,  sorted_values_baseline, label='AMIS (\\nu={})'.format(dof))\n",
    "#         plt.plot(sorted_numsamples_ours,  sorted_values_ours, label='escort AMIS  (\\nu={})'.format(dof))\n",
    "#\n",
    "#         plt.fill_between(sorted_numsamples_baseline, sorted_values_baseline -   sorted_values_baseline_std, sorted_values_baseline +   sorted_values_baseline_std, alpha=0.1)\n",
    "#         plt.fill_between(sorted_numsamples_ours, sorted_values_ours -   sorted_values_ours_std, sorted_values_ours +   sorted_values_ours_std, alpha=0.1)\n",
    "#\n",
    "# plt.axhline(y=truth, color='r', linestyle='solid', lw=2, label='Estimated true value (with $10^5$ samples)')\n",
    "# plt.xlabel('Number of samples')\n",
    "# plt.ylabel(r'$\\hat{Z} value$')\n",
    "# plt.tight_layout()\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.savefig('./results/creatinine_meanZ.pdf',bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sorted_numsamples_baseline = sorted(list(map(int, results_baseline['meanalphaESSbaseline.npy'].keys())))\n",
    "# sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "# # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "# sorted_values_baseline = [ results_baseline['meanalphaESSbaseline.npy'][key] for key in sorted_numsamples_baseline_str]\n",
    "#\n",
    "# sorted_numsamples_ours = sorted(list(map(int, results_our_fixed_dof['25meanalphaESS.npy'].keys())))\n",
    "# sorted_numsamples_ours_str = [str(num) for num in sorted_numsamples_ours]\n",
    "# # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "# sorted_values_ours = [ results_our_fixed_dof['25meanalphaESS.npy'][key] for key in sorted_numsamples_ours_str]\n",
    "#\n",
    "#\n",
    "# plt.plot(sorted_numsamples_baseline[:len(sorted_numsamples_baseline) -  3],  sorted_values_baseline[:len(sorted_numsamples_baseline) -  3], label='AMIS (dof=3)')\n",
    "# plt.plot(sorted_numsamples_ours[:len(sorted_numsamples_ours) -  3],  sorted_values_ours[:len(sorted_numsamples_ours) -  3], label='escort AMIS  (dof=3)')\n",
    "# plt.xlabel('Number of samples')\n",
    "# plt.ylabel('alphaESS')\n",
    "# plt.legend()\n",
    "# plt.savefig('./results/creatinine_alphaESS.pdf')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sorted_numsamples_baseline = sorted(list(map(int, results_baseline['25meanZbaseline.npy'].keys())))\n",
    "# sorted_numsamples_baseline_str = [str(num) for num in sorted_numsamples_baseline]\n",
    "# # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "# sorted_values_baseline = [ results_baseline['25meanZbaseline.npy'][key] for key in sorted_numsamples_baseline_str]\n",
    "#\n",
    "# sorted_numsamples_ours = sorted(list(map(int, results_our_fixed_dof['25meanZ.npy'].keys())))\n",
    "# sorted_numsamples_ours_str = [str(num) for num in sorted_numsamples_ours]\n",
    "# # Step 2: Iterate through the sorted keys and get the corresponding values\n",
    "# sorted_values_ours = [ results_our_fixed_dof['25meanZ.npy'][key] for key in sorted_numsamples_ours_str]\n",
    "#\n",
    "#\n",
    "# plt.plot(sorted_numsamples_baseline[:len(sorted_numsamples_baseline) -  3],  sorted_values_baseline[:len(sorted_numsamples_baseline) -  3], label='AMIS (dof=3)')\n",
    "# plt.plot(sorted_numsamples_ours[:len(sorted_numsamples_ours) -  3],  sorted_values_ours[:len(sorted_numsamples_ours) -  3], label='escort AMIS  (dof=3)')\n",
    "# plt.axhline(y=sorted_values_ours[-1], color='r', linestyle='solid', lw=2, label='Estimated true value (with 6e+4 samples)')\n",
    "#\n",
    "# plt.xlabel('Number of samples')\n",
    "# plt.ylabel('mean Z value')\n",
    "# plt.legend()\n",
    "# plt.savefig('./results/creatinine_meanZ_estimation.pdf')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print('Estimate by AMIS', mean_Z_baseline[-1], std_Z_baseline[-1])\n",
    "# print('Estimate by alpha AMIS', mean_Z[-1], std_Z[-1])\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print('ESS by AMIS', mean_ESS_baseline[-1], 1.96* std_ESS_baseline[-1])\n",
    "# print('alpha ESS by AMIS', mean_alphaESS_baseline[-1], 1.96*std_alphaESS_baseline[-1])\n",
    "# print('ESS by escort moment AMIS', mean_ESS[-1], 1.96*std_ESS[-1])\n",
    "# print('alpha ESS by by escort moment AMIS', mean_alphaESS[-1], 1.96* std_alphaESS[-1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Old: comparison with MCMC via KSD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def numpy_callback(x):\n",
    "#   # Need to forward-declare the shape & dtype of the expected output.\n",
    "#   result_shape = jax.core.ShapedArray(x.shape, x.dtype)\n",
    "#   return jax.pure_callback(np.sin, result_shape, x)\n",
    "\n",
    "def log_density_gradient_correct(theta):\n",
    "    return bridgestan_model.log_density_gradient(theta)[1]\n",
    "\n",
    "def log_density_gradient(theta):\n",
    "    result_shape = jax.core.ShapedArray(theta.shape , theta.dtype)\n",
    "    # _, gradient = bridgestan_model.log_density_gradient(theta)\n",
    "    gradient = jax.experimental.io_callback(log_density_gradient_correct, result_shape, theta)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# compare results with MCMC via the KSD\n",
    "ksd_mcmc_samples = old_ksd(mcmc_samples_array, log_density_gradient)\n",
    "print(\"KSD using true samples:\", ksd_mcmc_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "final_samples = adapted_proposal.rvs(size=50000)\n",
    "\n",
    "weights = bridgestan_model.log_density(final_samples) - adapted_proposal.logpdf(final_samples)\n",
    "normalized_weights = np.exp(weights - logsumexp(weights))\n",
    "ksd_fixed_dof = old_ksd(final_samples, log_density_gradient, weights=normalized_weights)\n",
    "print(\"KSD for adapted proposal samples:\", ksd_fixed_dof)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
