{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Example E.5.3. BAYESIAN STUDENT-T REGRESSION from https://openreview.net/pdf?id=HltJfwwfhX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pystan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import rpy2py\n",
    "import rpy2.robjects as ro\n",
    "import json\n",
    "import jax\n",
    "from collections import OrderedDict\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "from amis_algorithms import alpha_AMIS_fixed_dof, AMIS_student_fixed_dof\n",
    "\n",
    "import bridgestan\n",
    "\n",
    "from utils import old_ksd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable LaTeX for nicer plotting\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "\n",
    "# from tueplots import bundles\n",
    "# plt.rcParams.update(bundles.aistats2023())\n",
    "\n",
    "from experiments_amis import run_AMIS_real_dataset\n",
    "\n",
    "\n",
    "# Load and prepare the dataset\n",
    "url = \"https://github.com/faosorios/heavy/blob/master/data/creatinine.rda?raw=true\"\n",
    "with requests.get(url) as resp:\n",
    "    with open(\"creatinine.rda\", \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "\n",
    "# Load RDA file into Python\n",
    "ro.r['load'](\"creatinine.rda\")\n",
    "df = pandas2ri.rpy2py_dataframe(ro.r['creatinine'])\n",
    "\n",
    "data_df = pd.DataFrame(columns=['log_SC', 'log_WT', 'log_140_minus_A', 'log_CR'])\n",
    "\n",
    "# Apply transformations following https://openreview.net/pdf?id=HltJfwwfhX\n",
    "data_df['log_SC'] = np.log(df['SC'])\n",
    "data_df['log_WT'] = np.log(df['WT'])\n",
    "data_df['log_CR'] = np.log(df['CR'])\n",
    "data_df['log_140_minus_A'] = np.log(140 - df['Age'])\n",
    "data_df = data_df.dropna() # remove any rows with NaN values after transformation\n",
    "\n",
    "# Compile the Stan model\n",
    "sm = pystan.StanModel(file=\"./student_reg_model.stan\")\n",
    "\n",
    "# Prepare data for Stan model\n",
    "data_for_stan = {\n",
    "    'N': len(data_df),\n",
    "    'x1': data_df['log_SC'].values.tolist(),\n",
    "    'x2': data_df['log_WT'].values.tolist(),\n",
    "    'x3': data_df['log_140_minus_A'].values.tolist(),\n",
    "    'y': data_df['log_CR'].values.tolist()  # response variable\n",
    "}\n",
    "\n",
    "# Save the data dictionary to a JSON file\n",
    "with open(\"student_regression_data.json\", \"w\") as f:\n",
    "    json.dump(data_for_stan, f, indent=4)\n",
    "\n",
    "\n",
    "# Fit the model and sample from the posterior using NUTS (NUTS paper: https://arxiv.org/abs/1111.4246)\n",
    "fit = sm.sampling(data=data_for_stan, iter=100, chains=1)\n",
    "mcmc_samples = fit.extract()\n",
    "\n",
    "stan = \"./student_reg_model.stan\"\n",
    "data = \"./student_regression_data.json\"\n",
    "bridgestan_model = bridgestan.StanModel.from_stan_file(stan, data)\n",
    "\n",
    "true_log_pdf = fit.log_prob\n",
    "\n",
    "# Step 3: Find the MAP solution\n",
    "map_sol = sm.optimizing(data=data_for_stan)\n",
    "\n",
    "# Retrieve the values, extract the single element from each array, and convert to an ndarray\n",
    "map_sol_array = np.array([value.item() for value in map_sol.values()])\n",
    "\n",
    "map_sol_list = list(map_sol.values())\n",
    "log_dens_at_map, _, hessian_at_map = bridgestan_model.log_density_hessian(theta_unc=map_sol_array, propto=True)\n",
    "\n",
    "dim = 4 # Fixed\n",
    "dof_proposal = 3\n",
    "mu_initial_proposal_laplace = map_sol_array\n",
    "\n",
    "assert np.isclose(log_dens_at_map, fit.log_prob(map_sol_list))\n",
    "\n",
    "# Negative inverse of the Hessian at the MAP solution used as covariance\n",
    "cov_laplace = -np.linalg.inv(hessian_at_map)\n",
    "assert np.all(np.linalg.eigvals(cov_laplace) > 0)\n",
    "shape_initial_proposal_laplace = (dof_proposal - 2) / (dof_proposal) * cov_laplace\n",
    "\n",
    "\n",
    "sigma_initial = 10\n",
    "shape_initial = (dof_proposal - 2) / (dof_proposal) * sigma_initial * np.identity(dim)\n",
    "\n",
    "\n",
    "num_samples = int(1e5)\n",
    "n_iter = 25\n",
    "nb_runs = 100\n",
    "\n",
    "# random_mu_initial = np.random.multivariate_normal(mean=np.zeros(dim), cov=np.identity(dim), size=1)\n",
    "# random_mu_initial = np.random.uniform(-1, 1, dim)\n",
    "# shape_initial_proposal = (dof_proposal - 2) / (dof_proposal) * np.identity(dim)\n",
    "mu_initial = np.ones(dim)\n",
    "\n",
    "assert np.all(np.linalg.eigvals(shape_initial_proposal_laplace) > 0)\n",
    "\n",
    "mean_Z_baseline, std_Z_baseline, mean_ESS_baseline, mean_alphaESS_baseline, std_ESS_baseline, std_alphaESS_baseline = run_AMIS_real_dataset(alg=AMIS_student_fixed_dof, nb_runs=nb_runs, n_iterations=n_iter, log_pi_tilde=true_log_pdf, dof_proposal=dof_proposal, M=num_samples, d=dim, mu_initial=mu_initial, shape_initial=shape_initial)\n",
    "\n",
    "\n",
    "mean_Z, std_Z, mean_ESS, mean_alphaESS, std_ESS, std_alphaESS = run_AMIS_real_dataset(alg=alpha_AMIS_fixed_dof, nb_runs=nb_runs, n_iterations=n_iter, log_pi_tilde=true_log_pdf, dof_proposal=dof_proposal, M=num_samples, d=dim, mu_initial=mu_initial, shape_initial=shape_initial)\n",
    "\n",
    "# Last key is the log probability, which we don't want\n",
    "exclude_key = \"lp__\"\n",
    "mcmc_samples = OrderedDict((k, v) for k, v in mcmc_samples.items() if k != exclude_key)\n",
    "\n",
    "mcmc_samples_array = np.vstack(list(mcmc_samples.values())).T"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define confidence interval multiplier for 95% confidence\n",
    "ci_multiplier = 1.96\n",
    "\n",
    "# Create the first plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(len(mean_Z_baseline)), mean_Z_baseline, yerr=std_Z_baseline * ci_multiplier, fmt='o', label='$Z_{baseline}$')\n",
    "plt.title(r'Mean $Z_{baseline} \\pm 1.96 \\sigma$')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create the second plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(len(mean_ESS_baseline)), mean_ESS_baseline, yerr=std_ESS_baseline * ci_multiplier, fmt='o', label='$ESS_{baseline}$')\n",
    "plt.errorbar(range(len(mean_alphaESS_baseline)), mean_alphaESS_baseline, yerr=std_alphaESS_baseline * ci_multiplier, fmt='s', label='$\\\\alpha ESS_{baseline}$')\n",
    "plt.title(r'Mean $ESS_{baseline} \\pm 1.96 \\sigma$ and Mean $\\\\alpha ESS_{baseline} \\pm 1.96 \\sigma$')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def numpy_callback(x):\n",
    "#   # Need to forward-declare the shape & dtype of the expected output.\n",
    "#   result_shape = jax.core.ShapedArray(x.shape, x.dtype)\n",
    "#   return jax.pure_callback(np.sin, result_shape, x)\n",
    "\n",
    "def log_density_gradient_correct(theta):\n",
    "    return bridgestan_model.log_density_gradient(theta)[1]\n",
    "\n",
    "def log_density_gradient(theta):\n",
    "    result_shape = jax.core.ShapedArray(theta.shape , theta.dtype)\n",
    "    # _, gradient = bridgestan_model.log_density_gradient(theta)\n",
    "    gradient = jax.experimental.io_callback(log_density_gradient_correct, result_shape, theta)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# compare results with MCMC via the KSD\n",
    "ksd_mcmc_samples = old_ksd(mcmc_samples_array, log_density_gradient)\n",
    "print(\"KSD using true samples:\", ksd_mcmc_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "final_samples = adapted_proposal.rvs(size=50000)\n",
    "\n",
    "weights = bridgestan_model.log_density(final_samples) - adapted_proposal.logpdf(final_samples)\n",
    "normalized_weights = np.exp(weights - logsumexp(weights))\n",
    "ksd_fixed_dof = old_ksd(final_samples, log_density_gradient, weights=normalized_weights)\n",
    "print(\"KSD for adapted proposal samples:\", ksd_fixed_dof)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
